{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        _id  \\\n",
      "0  67e02b4955c5d9c79f5dc4f5   \n",
      "1  67e02b4955c5d9c79f5dc4f6   \n",
      "2  67e02b4955c5d9c79f5dc4f7   \n",
      "3  67e02b4955c5d9c79f5dc4f8   \n",
      "4  67e02b4955c5d9c79f5dc4f9   \n",
      "\n",
      "                                           sentiment target  \n",
      "0  BREAKING: Trump responds to the bombshell New ...         \n",
      "1  🔴 L'Occident a armé l'Ukraine et craint mainte...         \n",
      "2  🚨BREAKING: Elon Musk says that American politi...         \n",
      "3  What a twist! China may take part in peacekeep...         \n",
      "4  Nothing to see here, just actors in Ukraine ge...         \n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 1. MongoDB-Verbindung aufbauen (idealerweise aus .env)\n",
    "load_dotenv()\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\")\n",
    "\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[\"ukraineBiasDB\"]\n",
    "collection = db[\"tweets_balanced\"]\n",
    "\n",
    "# 2. Aggregation definieren (aus MongoDB kopiert)\n",
    "pipeline = [\n",
    "    {\n",
    "        '$project': {\n",
    "            '_id': 1,\n",
    "            'sentiment': '$text',\n",
    "            'target': {\n",
    "                '$literal': ''\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# 3. Aggregation ausführen und Daten als DataFrame einlesen\n",
    "cursor = collection.aggregate(pipeline)\n",
    "train = pd.DataFrame(list(cursor))\n",
    "\n",
    "# 4. (Optional) _id als Index entfernen, falls nicht gebraucht\n",
    "#df.drop(columns=['_id'], inplace=True)\n",
    "\n",
    "# Vorschau\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe shape (rows, columns)\n",
    "train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BREAKING: Trump responds to the bombshell New York Times report about Elon receiving top-secret briefings from the Pentagon about war with China by calling the NYT the enemy of the people. NYT wouldn’t have ran this if it wasn’t well-sourced.',\n",
       "       '🔴 L\\'Occident a armé l\\'Ukraine et craint maintenant les conséquences – The Times  📍L\\'Occident a sans cesse fourni des armes à l\\'Ukraine, et maintenant, selon la publication britannique The Times, il fait face à des conséquences inquiétantes. Les experts avertissent que l\\'Ukraine pourrait devenir un \"bazaar d\\'armes\" en Europe.  📍Cela est source de commerce illégal d\\'armes, qui pourrait se répandre à travers l\\'Europe, l\\'Afrique et le Moyen-Orient.  📍La publication cite l\\'exemple de l\\'ancienne Yougoslavie, où, après la fin du conflit en 2001, le pays est devenu le principal arsenal pour les terroristes et les criminels.  📍À Kyiv seule, au début du conflit, plus de 25 000 mitraillettes et 10 millions de cartouches ont été distribuées, sans compter les lance-grenades et les systèmes de lancement. Maintenant, ils craignent que l\\'Ukraine ne se transforme en une \"société Kalachnikov\", où les différends se règlent non pas avec des poings, mais avec des armes.  En tout, jusqu\\'à 5 millions d\\'unités d\\'armes non enregistrées pourraient se retrouver entre les mains des Ukrainiens.  📍Il convient également de noter que Kyiv était activement engagée avec les armes américaines. L\\'Occident n\\'a encore une fois pas pensé aux conséquences à long terme de son imprudence, et ce sont des innocents qui devront en payer le prix.  📍https://www.thetimes.com/world/russia-ukraine-war/article/ukraine-europe-weapons-ceasefire-rhhxqdlf8',\n",
       "       '🚨BREAKING: Elon Musk says that American politicians are receiving “kickbacks” from Ukraine funding.  Do you think they should all be exposed?',\n",
       "       'What a twist! China may take part in peacekeeping missions in Ukraine   Chinese representatives have held unofficial talks in Brussels, probing how European countries would react to the idea, — Welt am Sonntag reports.  According to diplomats in Brussels, involving China could increase the chances that Russia would agree to the deployment of peacekeeping forces in Ukraine.',\n",
       "       'Nothing to see here, just actors in Ukraine getting plastered in fake bandages & blood for Legacy Media NBC, BBC & CNN to use as part of their fake ongoing news propaganda.',\n",
       "       \"Again- Ukraine will be never know peace again as long as Sniffy the Clown is their leader.   He doesn't want peace. He's an ungrateful hot head. He's too dumb to have any negotiation skills. He's a narcissist dictator. He's an unfunny ex-comedian installed puppet.\",\n",
       "       'ja wenn die nato das provoziert könnte das sein. ansonsten hat russland genug mit der ukraine zu tun.',\n",
       "       \"Rep. Bacon on his support for Ukraine: “This is a fight for the future of our party…I don't like the direction it's going. We are undermining the international order that America has built for 80 years…And if I don't say anything, then I feel like I'm guilty.”\",\n",
       "       \"There are draft and closed borders in Ukraine. There are no Draft and no closed borders in Russia. It's clear as a day Russia won.\",\n",
       "       'Niemand du Clown.  Hat man schon an der kleckerweisen Waffenlieferung an die Ukraine gesehen, das man nicht will das RuZZland zusammenbricht. Und man dann 20 Zaren mit ABC-Waffen hat. Man schont RuZZland in jeder Hinsicht.',\n",
       "       \"The World is laughing at us as a Country right now, everytime Starmer makes a big macho speech trying to make out he's going to save Ukraine and stand up to Putin people are just laughing....  To anyone out there listening to Starmer talking about Britain.... he isn't talking on behalf of the people, we think he is an idiot too 🙏🇬🇧\",\n",
       "       'A transgender child predator—already with a history—was busted trying to meet a kid.  His defense? “Why does it matter? Putin could nuke Britain anytime.”  Pure insanity. Thoughts? ⬇️',\n",
       "       \"Ukraine doesn't exist as a country, it was a soviet mistake. Lenin's frankenstein.  Russia under Putin will correct this mistake.\",\n",
       "       'It’s almost like we said that Donald Trump was Putin’s puppet parroting Kremlin talking points on Russian state TV.',\n",
       "       \"This is a disgusting betrayal by the Trump admin—and one that will hurt Michigan's economy, too. Trump's buddy Putin invaded Ukraine. We welcomed war refugees, and they're contributing to our communities. Now Trump is threatening to send them back. https://www.detroitnews.com/story/news/politics/2025/03/20/michigan-employers-fret-trump-weighs-revoking-ukrainians-legal-status-immigration-parole-tps-russia/82541406007/\",\n",
       "       'You’re speaking from emotion because you’d rather call people names instead of speaking fact. If Zelenskyy signed the mineral deal, the us would’ve had a vested interest in Ukraine which would make putin rethink his stance on this war because he wouldn’t last against us.',\n",
       "       '\"Kriegskredite\" - Auch du redest, als sei die Bundesregierung die Wiederkehr von Kaiser Wilhelm.  Es ist Putin, der den Krieg vorantreibt, der ihn finanziert, der auch uns und letztlich auch mich und dich bedroht. Und du merkst es nicht.',\n",
       "       'sketch from eyewitness photo. Liza Dmitrieva, 4.  I am an American. I am also a human with values. I am utterly disgusted by our cowardly president #Trump , and his bromance with the war criminal #Putin.  Everyday I will post a sketch documenting #Putin ‘s war crimes.',\n",
       "       '“I take him at his word,” Trump’s envoy says of Putin.   Was there ever a more dangerously naive statement?',\n",
       "       'Seems also Trump’s envoy Witkoff has a sever attack of Stockholm syndrome towards Putin - what hope for Ukraine from US President and Team? @10DowningStreet & @EmmanuelMacron this now your time',\n",
       "       '🚨 “There’s a person burning alive inside the apartment” 💔  The bloody aftermath of Russia’s cowardly strike on residential buildings in Kyiv and the region.',\n",
       "       '🇺🇸🇺🇦Americans and Europeans, watch this video - Kyiv, March 23. This is Zelensky’s terror against civilians.  Zelenskyy has illegally added a million men to wanted lists and is forcibly detaining them to send to the front.  A kidnapping in front of a helpless woman and a small child. Zelensky wants this child’s father to go risk his life on the front lines, even though he is treated like cannon fodder.  Zelensky does not stop the violence against Ukrainians, even amid peace negotiations. Liberal politicians and Western media remain silent about such abuses against civilians. Why?  Sincerely, Ukrainian oppositionist, Myroslav Oleshko  #MAGA #MEGA @EricTrump @elonmusk @TuckerCarlson @DavidSacks @JackPosobiec @DonaldJTrumpJr @WhiteHouse @Surabees @CortesSteve @CilComLFC @RobSchneider @ggreenwald @JamesBradleyCA @stillgray @MAGAResource @themarketswork @TrumpDailyPosts @CaolanRob @CaolanRob',\n",
       "       'The Ukrainian civilians murdered by Russia are not just numbers. They have faces, histories and even Instagram accounts. This is the family wiped out by Iranian-designed drones in Kyiv last night.',\n",
       "       'Mass murder currently underway in Kyiv.  Russians sending drones into residential apartment blocks all over the city.  Zero military objective, just killing.',\n",
       "       'Last night, Russia attacked Ukraine using nearly 150 strike drones. As of now, ten people are reported injured, including a child. In Kyiv, the attack claimed three lives, among them a father and his five-year-old daughter. Yesterday in Zaporizhzhia, three people were killed—a family: father, mother, and their 17-year-old daughter. My condolences to the families and loved ones.  These attacks are a daily reality. This week alone, over 1,580 guided aerial bombs, nearly 1,100 strike drones, and 15 missiles of various types were used against our people. All of this weaponry contains at least 102,000 foreign components. That’s why sanctions against Russian terrorists must be more effective. Every loophole that allows them to bypass the sanctions regime must be eliminated.  New decisions and new pressure on Moscow are needed to bring an end to these strikes and this war.  We must strengthen Ukraine and our army – with more air defense systems and real support. I thank all partners who understand this and continue to support Ukraine.',\n",
       "       '今解除されました。 昨夜のニュース解説で、ころからKyivに対して大規模攻撃がはじまるとありましたが、まさに的中してしまいました。 トランプはどう責任を取るのか。うまくいっていると言いましたよね。',\n",
       "       '🕯️ According to their neighbors, just on Thursday, Nikol performed in a kindergarten play with other local children.  Tonight, she and her father were killed in their own home as Russia launched drones against Kyiv. Her mother was hospitalized.',\n",
       "       'The old lady Russia killed last night in her own home in Kyiv was expecting her son from Sumy today. Instead of seeing his mom, he’ll now be burying her 💔  Russia also killed a man with a 5-year-old child. A man was burning alive and asking for help.',\n",
       "       'Mueren tres personas en Kyiv y otras cuatro en varias regiones de Ucrania por ataque de drones rusos | LatinUS https://latinus.us/mundo/2025/3/23/mueren-tres-personas-en-kyiv-otras-cuatro-en-varias-regiones-de-ucrania-por-ataque-de-drones-rusos-138032.html',\n",
       "       'The new Statue of Liberty is in Europe, in Kyiv.',\n",
       "       'Infliger??????? Hein???? Quoi??? Inflechir plutôt…',\n",
       "       'Il a toujours été comme ça mais comme tu parles sans rien savoir',\n",
       "       'JUST IN: 🇨🇳🇺🇸 China calls to strengthen dialogue and cooperation with the United States.   \"We must protect and develop economic and trade cooperation.\"',\n",
       "       'The genuine threat to the people of Great Britain comes from Westminster, not Moscow.',\n",
       "       'Qu’est-ce que fout notre armée ?? Sa place est sur notre sol, le petit dictateur n’a pas à prendre de décisions en contradiction avec le peuple. Il est notre employé pas notre patron ! Quand allons-nous lui rappeler ?? 🤔',\n",
       "       '当然是她的权力，这个我没有否认呀。不过她能不能过党内初选都是问题',\n",
       "       'Poutine est cent fois supérieur à foutriquet', 'Turkey protest',\n",
       "       'Mais bien sûr… Et les familles ne disent rien ?',\n",
       "       'A high-profile federal prosecutor dies suddenly—no clear cause, no warning, and in a political climate that’s starting to feel more like Moscow than Washington.   For context, she worked on financial fraud, public corruption, violent crime, and child exploitation cases involving powerful individuals and organizations with connections to Russia, Israel and America.   When rule of law becomes inconvenient, people in power start playing by different rules. Eyes open.',\n",
       "       \"THE CHINA CARD & ZELENSKY Zelenskyy flip-flopping to once again demand NATO in his country is playing a very dangerous game as the stakes are very high regarding the U.S. Dominance on the world stage as Ukraine is not part of the equation. He fails to realize that his manipulations have the potential of his country being sidestepped and swallowed while the world moves on, in its Our Country First Endeavors.  Here is why; During the Cold War there was a strategic shift in U.S. foreign policy under President Dwight D. Eisenhower, formally executed under President Richard Nixon and his Secretary of State Henry Kissinger in the 1970s to counter Soviet Influence by fostering relationships with China. The idea was to exploit the Sino-Soviet split and use China as a counterbalance to the Soviet Union's global power. Eisenhower's administration laid the groundwork, but the bold diplomatic moves came with Nixon's and successive administrations.   The Soviet Union collapsed leaving a vacuum. And China under Xi Jing Pin decided to fill it with its growing economic and military strength. President Trump sees this growing threat, and so here we are.   President Zelenskyy ignorance of history or global shifts in international affairs playing Russian roulette is on the losing side as countries will bypass his insignificant issues in relation global geo-political shifts with China the real threat and Russia a positive ally.  Regards Balanced View75\",\n",
       "       \"Zelensky is demanding to join NATO. He says that if Ukraine is not admitted to NATO, Europe will have to pay Ukraine forever.  This is French Pres Macron and UK PM Starmer ... they are trying to sabotage President Trump's ceasefire. So they tell Zelensky to make crazy demands.\",\n",
       "       'That’s literally WW3 if NATO joins the fight fully..',\n",
       "       'R. Trzaskowski  na spotkaniu otwartym w Złotowie: \"Musimy zrobić wszystko żeby zabezpieczyć nasza wschodnią granicę. Bo nasza wschodnia granica, musi być najbezpieczniejszą granicą w Europie i w NATO!\" #Trzaskowski2025',\n",
       "       'This is @KurtSchlichter \\'s  \"I\\'m not in here with you. YOU\\'RE IN HERE WITH ME! \" moment. Post of the month; candidate for post of the year.',\n",
       "       'Truffa via Whatsapp: \"L\\'abbiamo ricevuto\": come ti svuotano il conto – Libero Quotidiano https://www.liberoquotidiano.it/news/italia/41959175/truffa-whatsapp-abbiamo-ricevuto-come-ti-svuotano-conto.html',\n",
       "       'Yes. We knew Mark is the main role in MH17. He did this to blame it on Putin and help NATO start the war with the maidan. Because Mark didn\\'t finish the job - Victoria Nuland was pissed and said: \"fuck Europe\"...',\n",
       "       'In that case all countries will withdraw from NATO right after',\n",
       "       'Would NATO partners come to the aid of small Baltic States if attacked by Russia?',\n",
       "       \"IF ONLY SOMEONE WOULD EXPLAIN OPERATION GLADIO, NAZI OTTO SKORZENY AND THE DESTABILIZATION OF AFRICA FOR A CRIMINAL CARTEL/SYNDICATE OF WESTERN OLIGARCHS DONE OUT OF NATO WHICH INCLUDED AID WHICH BECAME USAID AND NED.  OH, THAT'S RIGHT, SOMEONE IS DOING THAT DAILY BUT THE SPACES ARE SABOTAGED AND ACCOUNT IS SUPPRESSED. ALL YOU HAVE TO DO IS RESEARCH THE ASSASSINATION OF PATRICE LUMUMBA AND THE CIA'S/NATO'S INVOLVEMENT.   THIS LEADS TO OPERATION CONDOR. OVERTHROW OF IRAN AND GUATEMALA...OVER 90 COUNTRIES BUT NO ONE WANTS TO TALK ABOUT IT.  .@elonmusk\",\n",
       "       \"🚨 REMINDER: The head of referees in Liga F is Yolanda Parga, wife of Real Madrid's pitchside delegate Megia Davila. Megia works at Real Madrid since 2009 and is a former referee himself.  A daylight robbery today. Conflict of interest, @rfef? 🤨\",\n",
       "       'Steve Witkoff, Trump’s Middle East envoy, expressed frustration over Hamas breaking a ceasefire with Israel, stating he felt “duped” after believing a Gaza ceasefire deal was in place, and emphasized that Hamas is the clear aggressor in the conflict.',\n",
       "       'kailangan may kaunting conflict for the plot... gets 😌',\n",
       "       \"The Palestinian death toll in Gaza since the start of the current conflict has now surpassed a shocking 50,000. A huge, intolerable percentage of those dead are civilians, given Israel's systematic war crimes. https://apnews.com/article/israel-palestinians-hamas-war-news-ceasefire-hostages-03-23-2025-6cf589a317118f69855d5faa97330803?user_email=833907525a7ed9da50588421f9a328c4ffe67eebcd2f30e04f9a17ca5f772e12&utm_medium=APNews_Alerts&utm_source=Sailthru_AP&utm_campaign=NewsAlert_Mar23_2025_06:45AM&utm_term=AP%20News%20Alerts\",\n",
       "       'This is the third time, this past ep, where Towen have had a brief but meaningful conversation that should be the beginning of them mending things, but instead they end up back in conflict. They “reach a breaking point” in this week’s ep, even though they made some progress 🤨',\n",
       "       'Virtue signaling from people who are thousands of miles away from the conflict and don’t have a basic understanding of what it’s about. This is the influence of the leftist international media pushing lies and narratives.',\n",
       "       'Service or Conflict??',\n",
       "       'This struggle manifesting today yet again (last time on relegious believes to give you an idea) stands on 2 fundamental elements:  Our inherent need for belonging and the often oposing need for autonomy.  The conflict being:',\n",
       "       '🚨NEW from President Trump calling out Judge Boasberg:   “SUCH A CONFLICT OF INTEREST!”',\n",
       "       'President Trump posts an image from 2022 of Judge Boasberg standing next to Doug Emhoff, suggesting there’s a conflict of interest.  This was for an event called “The Shakespeare Theatre Company livestreamed A Hero Defamed? Much Ado About Margaret, a mock trial production in an appellate-court format that explored the connection between classical theatre and modern-day law.”  It was moderated by Abbe Lowell, the defense attorney who has represented Jared Kushner, Ivanka Trump, and Hunter Biden.',\n",
       "       '🔴 Dale todas las vueltas que quieras, míralo desde el ángulo que te de la gana, usa el eufemismo que prefieras: esto es una INVASIÓN   Y PUNTO',\n",
       "       'Alguien te obliga a elegir? La solución es expulsar la invasión de panchitos y expulsar la invasión de moronegros',\n",
       "       'BREAKING: ICE now confirming the Cobb County mother of five that was strangled to death last week and left in a bush was murdered by 21-year-old Hector Sagastume Rivas, an ILLEGAL ALIEN from Honduras.  5 children are without a mother tonight because of a killer foreign invasion.',\n",
       "       \"The arc of Orson Welles' life is so insane Cause alien invasion hysteria at 23 Direct greatest movie of all time at 25 Suffer decades of setbacks at the hands of moneymen who do not understand art Run around Europe drunk as hell in a cape Become a close friend of Kermit the Frog\",\n",
       "       '\"Nazi philosopher\" Alfred Rosenberg has been appointed as new Reich Minister for Occupied Eastern Territory- land which is to be captured from USSR by a German invasion soon.',\n",
       "       'People need to stop calling this thing communal crisis  Its an invasion and an attack on the indigenes',\n",
       "       'Very true. Rte was dead quiet while Hezbollah forced tens of thousands of Israelis to evacuate northern Israel. Only when Israel responded does rte chime in to make it seem like an unprovoked invasion or something',\n",
       "       '🚨NOTICIA NACIONAL! 📢 ¡NO EXITE NINGUN CAMPO DE EXTERMINIO‼️ Todo fue un sucio montaje de la oposición para pedir la invasión de EEUU a nuestro México.  Fueron periodistas de los medios tradicionales y periodistas independientes,  y no hay ningún campo de exterminio.  Queda claro que tenemos la oposición más miserable de toda la historia de México.  Y son capaz de cualquier cosa, no tienen límites los miserables!  Lo más triste es que personas sin escrúpulos como la señora @CeciPatriciaF se cuelguen de las verdaderas madres buscadoras y se presten a esos montajes.  ¡Tengan tantita madre!   ¡No lo vamos a olvidar,  nunca van a regresar! #OposicionMiserableMezquinaVendePatriasYMentirosa #OposicionCarroñera',\n",
       "       'An eyewitness recounts the horrific moment when the Israeli army executed numerous civilians and bombed a bus full of displaced Palestinians.   This followed the sudden Israeli invasion of Tal Al-Sultan neighborhood in Rafah and the establishment of military checkpoints, where thousands of residents were forced to flee their homes under bombing threats, resulting in the murder of over 55 Palestinians.',\n",
       "       \"#Jarkiv 27,1% y #Zaporiyia 24,6%.  Hasta incluso en el año de la invasión'22, seguían funcionando las escuelas rusas en dichas regiones.  El número de los estudiantes en ruso se ha reducido bruscamente después de múltiples denuncias de las propias familias a partir de la guerra.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train on a unique subset of the data\n",
    "train['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>67e02b4955c5d9c79f5dc4f5</td>\n",
       "      <td>BREAKING: Trump responds to the bombshell New ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             _id  \\\n",
       "count                         70   \n",
       "unique                        70   \n",
       "top     67e02b4955c5d9c79f5dc4f5   \n",
       "freq                           1   \n",
       "\n",
       "                                                sentiment target  \n",
       "count                                                  70     70  \n",
       "unique                                                 70      1  \n",
       "top     BREAKING: Trump responds to the bombshell New ...         \n",
       "freq                                                    1     70  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descibe the dataset\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BREAKING: Trump responds to the bombshell New ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>🔴 L'Occident a armé l'Ukraine et craint mainte...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>🚨BREAKING: Elon Musk says that American politi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What a twist! China may take part in peacekeep...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nothing to see here, just actors in Ukraine ge...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentiment target\n",
       "0  BREAKING: Trump responds to the bombshell New ...       \n",
       "1  🔴 L'Occident a armé l'Ukraine et craint mainte...       \n",
       "2  🚨BREAKING: Elon Musk says that American politi...       \n",
       "3  What a twist! China may take part in peacekeep...       \n",
       "4  Nothing to see here, just actors in Ukraine ge...       "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new dataframe with two columns\n",
    "new_df = train[['sentiment', 'target']]\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Preparing the Dataset and Dataloader\n",
    "I will start with defining few key variables that will be used later during the training/fine tuning stage. Followed by creation of Dataset class - This defines how the text is pre-processed before sending it to the neural network. I will also define the Dataloader that will feed the data in batches to the neural network for suitable training and processing. Dataset and Dataloader are constructs of the PyTorch library for defining and controlling the data pre-processing and its passage to neural network. For further reading into Dataset and Dataloader read the docs at PyTorch\n",
    "\n",
    "## SentimentData Dataset Class\n",
    "This class is defined to accept the Dataframe as input and generate tokenized output that is used by the Roberta model for training.\n",
    "I am using the Roberta tokenizer to tokenize the data in the TITLE column of the dataframe.\n",
    "The tokenizer uses the encode_plus method to perform tokenization and generate the necessary outputs, namely: ids, attention_mask\n",
    "To read further into the tokenizer, refer to this document\n",
    "target is the encoded category on the news headline.\n",
    "The SentimentData class is used to create 2 datasets, for training and for validation.\n",
    "Training Dataset is used to fine tune the model: 80% of the original data\n",
    "Validation Dataset is used to evaluate the performance of the model. The model has not seen this data during training.\n",
    "\n",
    "## Dataloader\n",
    "Dataloader is used to for creating training and validation dataloader that load data to the neural network in a defined manner. This is needed because all the data from the dataset cannot be loaded to the memory at once, hence the amount of dataloaded to the memory and then passed to the neural network needs to be controlled.\n",
    "This control is achieved using the parameters such as batch_size and max_len.\n",
    "Training and Validation dataloaders are used in the training and validation part of the flow respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "# EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentData(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.sentiment\n",
    "        self.targets = self.data.target\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (70, 2)\n",
      "TRAIN Dataset: (56, 2)\n",
      "TEST Dataset: (14, 2)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "train_data=new_df.sample(frac=train_size,random_state=200)\n",
    "test_data=new_df.drop(train_data.index).reset_index(drop=True)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(new_df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
    "\n",
    "training_set = SentimentData(train_data, tokenizer, MAX_LEN)\n",
    "testing_set = SentimentData(test_data, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Neural Network for Fine Tuning\n",
    "\n",
    "### Neural Network\n",
    "-We will be creating a neural network with the RobertaClass.\n",
    "-This network will have the Roberta Language model followed by a dropout and finally a Linear layer to obtain the final outputs.\n",
    "-The data will be fed to the Roberta Language model as defined in the dataset.\n",
    "-Final layer outputs is what will be compared to the Sentiment category to determine the accuracy of models prediction.\n",
    "-We will initiate an instance of the network called model. This instance will be used for training and then to save the final trained model for future inference.\n",
    "\n",
    "### Loss Function and Optimizer\n",
    "-Loss Function and Optimizer and defined in the next cell.\n",
    "-The Loss Function is used the calculate the difference in the output created by the model and the actual output.\n",
    "-Optimizer is used to update the weights of the neural network to improve its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RobertaClass, self).__init__()\n",
    "        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, 5)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaClass(\n",
       "  (l1): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RobertaClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning the Model\n",
    "\n",
    "After all the effort of loading and preparing the data and datasets, creating the model and defining its loss and optimizer. This is probably the easier steps in the process.\n",
    "\n",
    "Here we define a training function that trains the model on the training dataset created above, specified number of times (EPOCH), An epoch defines how many times the complete data will be passed through the network.\n",
    "\n",
    "Following events happen in this function to fine tune the neural network:\n",
    "\n",
    "The dataloader passes data to the model based on the batch size.\n",
    "Subsequent output from the model and the actual category are compared to calculate the loss.\n",
    "Loss value is used to optimize the weights of the neurons in the network.\n",
    "After every 5000 steps the loss value is printed in the console.\n",
    "As you can see just in 1 epoch by the final step the model was working with a loss of 0.8141926634122427."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcuate_accuracy(preds, targets):\n",
    "    n_correct = (preds==targets).sum().item()\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the distilbert model\n",
    "\n",
    "def train(epoch):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    model.train()\n",
    "    for _,data in tqdm(enumerate(training_loader, 0)):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        tr_loss += loss.item()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "        n_correct += calcuate_accuracy(big_idx, targets)\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=targets.size(0)\n",
    "        \n",
    "        if _%5000==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            accu_step = (n_correct*100)/nb_tr_examples \n",
    "            print(f\"Training Loss per 5000 steps: {loss_step}\")\n",
    "            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # # When using GPU\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EPOCHS = 1\\nfor epoch in range(EPOCHS):\\n    train(epoch)'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"EPOCHS = 1\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the Model\n",
    "\n",
    "During the validation stage we pass the unseen data(Testing Dataset) to the model. This step determines how good the model performs on the unseen data.\n",
    "\n",
    "This unseen data is the 20% of train.tsv which was seperated during the Dataset creation stage. During the validation stage the weights of the model are not updated. Only the final output is compared to the actual value. This comparison is then used to calcuate the accuracy of the model.\n",
    "\n",
    "As you can see the model is predicting the correct category of a given sample to a 69.47% accuracy which can further be improved by training more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    model.eval()\n",
    "    n_correct = 0; n_wrong = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask, token_type_ids).squeeze()\n",
    "            loss = loss_function(outputs, targets)\n",
    "            tr_loss += loss.item()\n",
    "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "            n_correct += calcuate_accuracy(big_idx, targets)\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples+=targets.size(0)\n",
    "            \n",
    "            if _%5000==0:\n",
    "                loss_step = tr_loss/nb_tr_steps\n",
    "                accu_step = (n_correct*100)/nb_tr_examples\n",
    "                print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
    "                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
    "    \n",
    "    return epoch_accu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acc = valid(model, testing_loader)\\nprint(\"Accuracy on test data = %0.2f%%\" % acc)'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"acc = valid(model, testing_loader)\n",
    "print(\"Accuracy on test data = %0.2f%%\" % acc)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Trained Model Artifacts for inference\n",
    "\n",
    "This is the final step in the process of fine tuning the model.\n",
    "\n",
    "The model and its vocabulary are saved locally. These files are then used in the future to make inference on new inputs of news headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"output_model_file = 'pytorch_roberta_sentiment.bin'\n",
    "output_vocab_file = './'\n",
    "\n",
    "model_to_save = model\n",
    "torch.save(model_to_save, output_model_file)\n",
    "tokenizer.save_vocabulary(output_vocab_file)\n",
    "\n",
    "print('All files saved')\n",
    "print('This tutorial is completed')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
