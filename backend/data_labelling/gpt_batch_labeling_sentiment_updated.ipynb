{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ GPT-3.5 Auto-Labeling f√ºr geopolitische Tweets (neue OpenAI API kompatibel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai pymongo python-dotenv tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client_openai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "mongo_uri = os.getenv(\"MONGO_URI\")\n",
    "mongo_client = MongoClient(mongo_uri)\n",
    "collection = mongo_client[\"ukraineBiasDB\"][\"tweets_balanced\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1724 entries, 0 to 1723\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   _id     1724 non-null   object\n",
      " 1   text    1724 non-null   object\n",
      " 2   target  1724 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 40.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67e1ebdb42cf13ec74016b73</td>\n",
       "      <td>Fr multiverse played out.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67e1ebdb42cf13ec74016b76</td>\n",
       "      <td>‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ß‡πà‡∏≤ ‡∏™‡∏ß.‡∏Ñ‡∏ß‡∏£‡∏ä‡∏∞‡∏•‡∏≠‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ‡∏î‡πÜ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67e1ebdc42cf13ec74016c2c</td>\n",
       "      <td>\"FAFO_FROM_NAFO\" is locked, loaded and ready t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67e1e66a97acb2988dfdddb9</td>\n",
       "      <td>What's going on with signal that was supposed ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67e1e66b97acb2988dfdde96</td>\n",
       "      <td>The potential for conflict of interest is not ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  67e1ebdb42cf13ec74016b73   \n",
       "1  67e1ebdb42cf13ec74016b76   \n",
       "2  67e1ebdc42cf13ec74016c2c   \n",
       "3  67e1e66a97acb2988dfdddb9   \n",
       "4  67e1e66b97acb2988dfdde96   \n",
       "\n",
       "                                                text target  \n",
       "0                          Fr multiverse played out.         \n",
       "1  ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ß‡πà‡∏≤ ‡∏™‡∏ß.‡∏Ñ‡∏ß‡∏£‡∏ä‡∏∞‡∏•‡∏≠‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ‡∏î‡πÜ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢...         \n",
       "2  \"FAFO_FROM_NAFO\" is locked, loaded and ready t...         \n",
       "3  What's going on with signal that was supposed ...         \n",
       "4  The potential for conflict of interest is not ...         "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {\"$group\": {\"_id\": \"$text\", \"doc\": {\"$first\": \"$$ROOT\"}}},\n",
    "    {\"$replaceRoot\": {\"newRoot\": \"$doc\"}},\n",
    "    {\"$project\": {\"_id\": 1, \"text\": 1, \"target\": {\"$literal\": \"\"}}}\n",
    "]\n",
    "cursor = collection.aggregate(pipeline)\n",
    "df = pd.DataFrame(list(cursor))\n",
    "df = df[df['text'].notnull()].reset_index(drop=True)\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6236333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relevanz-Sicherstellung via GPT-API Call\n",
    "# funktioniert noch nicht deshalb auskommentiert\n",
    "# \n",
    "\"\"\"def gpt_filter_relevant(texts):\n",
    "    prompt = (\n",
    "        \"Du bekommst eine Liste mit Social Media Texten. \"\n",
    "        \"Bitte gib nur diejenigen zur√ºck, die sich thematisch mit dem Krieg zwischen Russland und der Ukraine besch√§ftigen \"\n",
    "        \"(z.‚ÄØB. geopolitische Ereignisse, Meinungen, milit√§rische Entwicklungen, etc).\\n\\n\"\n",
    "        \"Gib die Antwort als Liste von JSON-Objekten zur√ºck im Format:\\n\"\n",
    "        \"{\\\"text\\\": \\\"‚Ä¶\\\"}\\n\\n\"\n",
    "        \"Texte:\\n\"\n",
    "    )\n",
    "    for i, t in enumerate(texts):\n",
    "        prompt += f\"{i+1}. {t}\\n\"\n",
    "\n",
    "    try:\n",
    "        response = client_openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Fehler beim Filtern:\", e)\n",
    "        return None\n",
    "\n",
    "def filter_relevant_texts(df, batch_size=10):\n",
    "    relevant = []\n",
    "    total_checked = 0\n",
    "\n",
    "    for i in tqdm(range(0, len(df), batch_size), desc=\"üîç Filter Ukraine/Russia relevante Inhalte\"):\n",
    "        texts = df.iloc[i:i+batch_size][\"text\"].tolist()\n",
    "        result = gpt_filter_relevant(texts)\n",
    "        total_checked += len(texts)\n",
    "\n",
    "        if result:\n",
    "            try:\n",
    "                parsed = json.loads(result)\n",
    "                relevant.extend(parsed)\n",
    "            except Exception as e:\n",
    "                print(\"‚ö†Ô∏è Fehler beim Parsen (Filter):\", e)\n",
    "                print(result)\n",
    "\n",
    "        time.sleep(1.5)\n",
    "\n",
    "    print(f\"\\n‚úÖ Gepr√ºft: {total_checked}, Relevant: {len(relevant)}, Ausgeschieden: {total_checked - len(relevant)}\")\n",
    "\n",
    "    df_relevant = pd.DataFrame(relevant)\n",
    "    df_relevant.to_json(\"filtered_relevant_texts.json\", orient=\"records\", indent=2)\n",
    "    return df_relevant\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_label_batch(texts):\n",
    "    prompt = (\n",
    "        \"Bitte klassifiziere die folgenden Texte auf Basis ihrer geopolitischen Haltung:\\n\"\n",
    "        \"0 = Pro-Russland\\n1 = Neutral\\n2 = Pro-Ukraine\\n\\n\"\n",
    "        \"Gib die Antwort bitte als Liste von JSON-Objekten im Format: {\\\"text\\\": \\\"‚Ä¶\\\", \\\"label\\\": 0}\\n\\n\"\n",
    "        \"Texte:\\n\"\n",
    "    )\n",
    "    for i, t in enumerate(texts):\n",
    "        prompt += f\"{i+1}. {t}\\n\"\n",
    "\n",
    "    try:\n",
    "        response = client_openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå GPT API Fehler:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Optional: bisherigen Fortschritt laden\n",
    "partial_file = \"labeled_tweets_partial.json\"\n",
    "results = []\n",
    "\n",
    "if os.path.exists(partial_file):\n",
    "    df_existing = pd.read_json(partial_file)\n",
    "    results = df_existing.to_dict(orient=\"records\")\n",
    "    print(f\"üì¶ Fortsetzung ab Eintrag #{len(results)}\")\n",
    "else:\n",
    "    df_existing = pd.DataFrame()\n",
    "    print(\"üì¶ Neuer Lauf\")\n",
    "    \n",
    "batch_size = 10\n",
    "start_index = len(results)\n",
    "\n",
    "for i in tqdm(range(start_index, len(df), batch_size)):\n",
    "    batch = df.iloc[i:i+batch_size]['text'].tolist()\n",
    "    result = gpt_label_batch(batch)\n",
    "\n",
    "    if result:\n",
    "        try:\n",
    "            parsed = json.loads(result)\n",
    "            results.extend(parsed)\n",
    "\n",
    "            # üîê Speichern nach jedem erfolgreichen Batch\n",
    "            df_progress = pd.DataFrame(results)\n",
    "            df_progress.to_csv(\"labeled_tweets_partial.csv\", index=False)\n",
    "            df_progress.to_json(\"labeled_tweets_partial.json\", orient=\"records\", indent=2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"‚ö†Ô∏è Parsing-Fehler, Antwort wird √ºbersprungen\")\n",
    "            print(\"Antwort:\", result)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Leere Antwort von GPT\")\n",
    "\n",
    "    time.sleep(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f3c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Falls ein Abbruch im Langezeit-Job mit der GPT-API passiert hilft dieser Block:\n",
    "# Ergebnisse bis zum Abbruch sichern\n",
    "df_partial = pd.DataFrame(results)\n",
    "df_partial.to_csv(\"labeled_tweets_partial.csv\", index=False)\n",
    "df_partial.to_json(\"labeled_tweets_partial.json\", orient=\"records\", indent=2)\n",
    "\n",
    "print(f\"üíæ {len(df_partial)} Eintr√§ge gespeichert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_out = pd.DataFrame(results)\n",
    "# Speichern als Datei\n",
    "#df_out.to_csv(\"labeled_tweets.csv\", index=False)\n",
    "#df_out.to_json(\"labeled_tweets.json\", orient=\"records\", indent=2)\n",
    "\n",
    "# Speichern in MongoDB\n",
    "training_collection = mongo_client[\"ukraineBiasDB\"][\"labelled_tweets_training\"]\n",
    "docs = df_partial.to_dict(orient=\"records\")\n",
    "training_collection.insert_many(docs)\n",
    "\n",
    "print(f\"‚úÖ {len(docs)} Dokumente in 'labelled_tweets_training' gespeichert.\")\n",
    "\n",
    "# Printen der ersten 5 Zeilen zur Kontrolle\n",
    "df_partial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ed0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
